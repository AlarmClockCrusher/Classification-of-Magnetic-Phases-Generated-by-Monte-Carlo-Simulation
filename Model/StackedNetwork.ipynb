{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4395, 784) (4395, 1)\n",
      "The total size of dataset is  4395\n",
      "We will now select random 80% of the data as train data, and the rest serves as test data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "NumberOfPhases = 3\n",
    "#Read the labeled training set\n",
    "#The phases are skyrmions, ferromagnetic and spin spirals\n",
    "#Labels: skyrmions--0; ferromagnetic--1, spin spirals--2\n",
    "Skyrmions = pd.read_csv(\"/users/PAS1495/gsdbuilder/FinalProject/Model/SelectedPhases/Skyrmions_z.csv\")\n",
    "Ferromagnetics = pd.read_csv(\"/users/PAS1495/gsdbuilder/FinalProject/Model/SelectedPhases/Ferrogmanetic_z.csv\")\n",
    "Spirals = pd.read_csv(\"/users/PAS1495/gsdbuilder/FinalProject/Model/SelectedPhases/Spiral_z.csv\")\n",
    "\n",
    "#For a file will all the data, xspin is 0~783, yspin is 784~1567, zspin is 1568~2351,\n",
    "#Correspondingly, iloc[:, 0:784], iloc[:, 784:1568], iloc[:, 1568:2352]\n",
    "#For now, we will use the zspin first. A smaller file is used and the zspin is now 0~783.\n",
    "file = pd.DataFrame()\n",
    "file = pd.concat([file, Skyrmions])\n",
    "file = pd.concat([file, Ferromagnetics])\n",
    "file = pd.concat([file, Spirals])\n",
    "\n",
    "#Add the average zspin to the end of the array.\n",
    "data_dimz = file.iloc[:, 0:784].values\n",
    "data_ave_zspin = file.iloc[:, 788].values.reshape(-1, 1)\n",
    "print(data_dimz.shape, data_ave_zspin.shape)\n",
    "data_dimz_avez = np.append(data_dimz, data_ave_zspin, axis=1)\n",
    "\n",
    "#The label of the data is the column #2356\n",
    "data_labels = file.iloc[:, 789].values\n",
    "data_labels_onehot = np.zeros((len(data_labels), NumberOfPhases))\n",
    "for i in range(len(data_labels)):\n",
    "    data_labels_onehot[i][data_labels[i]] = 1\n",
    "    \n",
    "size = len(data_dimz)\n",
    "print(\"The total size of dataset is \", size)\n",
    "print(\"We will now select random 80% of the data as train data, and the rest serves as test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training and testing sample sizes are \n",
      "3516 879\n"
     ]
    }
   ],
   "source": [
    "#Shuffle the data before we choose our train/test dataset.\n",
    "new_order = np.random.permutation(range(size))\n",
    "train_range = new_order[0:int(0.8*size)] #The training sample is 80% of the total dataset.\n",
    "test_range = new_order[int(0.8*size):size]\n",
    "\n",
    "NumberOfPhases = 3\n",
    "x_train = data_dimz[train_range]\n",
    "y_train_onehot = data_labels_onehot[train_range]\n",
    "\n",
    "x_test = data_dimz[test_range]\n",
    "y_test = data_labels_onehot[test_range]\n",
    "\n",
    "print(\"The training and testing sample sizes are \")\n",
    "print(len(train_range), len(test_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x2b5847f57588> trainable?  False\n",
      "<keras.layers.core.Dense object at 0x2b5847f575f8> trainable?  False\n",
      "<keras.layers.core.Dense object at 0x2b5847f577b8> trainable?  False\n",
      "<keras.layers.core.Dense object at 0x2b5847f57898> trainable?  False\n",
      "<keras.layers.core.Lambda object at 0x2b5847f57b38> trainable?  False\n",
      "[[-0.56097114 -0.45866722 -0.6229448  ... -0.40006357 -0.38145673\n",
      "  -0.4939673 ]\n",
      " [-0.5550833  -0.46567804 -0.62535137 ... -0.41345727 -0.37177938\n",
      "  -0.4884244 ]\n",
      " [-0.5629843  -0.4667532  -0.63682044 ... -0.41286734 -0.38129795\n",
      "  -0.5018695 ]\n",
      " ...\n",
      " [-3.6175203  -3.515184   -3.2352068  ... -2.591853   -2.4889874\n",
      "  -3.0969837 ]\n",
      " [-2.1503935  -2.1226776  -1.9930882  ... -1.8141134  -1.9406321\n",
      "  -2.0287836 ]\n",
      " [-2.6645608  -2.1888058  -2.710416   ... -2.4153073  -2.215819\n",
      "  -2.4635484 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS1495/gsdbuilder/.local/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "#Load the trained encoder model\n",
    "encoder = load_model('fully_trained_encoder.h5')\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "    print(layer, \"trainable? \", layer.trainable)\n",
    "    \n",
    "print(encoder.predict(x_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 6,659\n",
      "Trainable params: 6,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1f1b33c2af51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# ==> The input to the decoder is the *third* output of the encoder ==> the z vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#The mean and variance output is not used here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vae_mlp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "latent_dim = 100\n",
    "intermediate_dim = 64\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "#\n",
    "# This is an intermediate layer for the decoder\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "#\n",
    "# The output layer has sigmoid activation (just like our normal autoencoder)\n",
    "# and the same dimension as our input\n",
    "outputs = Dense(NumberOfPhases, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "fcn = Model(latent_inputs, outputs, name='decoder')\n",
    "fcn.summary()\n",
    "plot_model(fcn, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "# instantiate VAE model\n",
    "# ==> This next line defines the output as the output of the decoder (of course)\n",
    "# ==> The input to the decoder is the *third* output of the encoder ==> the z vector\n",
    "#The mean and variance output is not used here.\n",
    "outputs = fcn(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "# Now compile our model!\n",
    "vae.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"summary\")\n",
    "print(vae.summary())\n",
    "plot_model(vae, to_file='vae_mlp.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 256\n",
    "history = stacked_network.fit(x_train, y_train_onehot, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test_onehot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda 5.2) [python/3.6-conda5.2]",
   "language": "python",
   "name": "sys_python36conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
